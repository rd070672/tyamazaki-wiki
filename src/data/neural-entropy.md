# Neural Entropyによる深層学習モデル評価

本稿は、拡散モデルにおける情報の消失と再注入を、非平衡熱力学の枠組みで定量化する Neural Entropy を整理する。Neural Entropyを評価軸として用いる際に、何を測っているか、何と比較できるか、どこに限界があるかを数式と実験事実に基づいて記述する。

### 参考ドキュメント
[1] A. Premkumar et al., Neural Entropy, OpenReview (NeurIPS 2025).  
https://openreview.net/forum?id=f6AYwCvynr
[2] 伊藤創祐, 確率熱力学・ゆらぎの定理とエントロピー生成（数理科学 2024 解説PDF）.  
https://sosuke110.com/surikagaku2024.pdf
[3] 東京大学 工学系研究科 プレスリリース（2025-08-01）, 非平衡熱力学の知見から拡散モデルの最適手法を提案.  
https://www.t.u-tokyo.ac.jp/press/pr2025-08-01-001


## 1. Neural Entropyが狙う評価対象
Neural Entropyは、拡散モデルがノイズからデータ分布へ戻る際に必要となる「追加の情報注入」を、ネットワークが担う補正の大きさとして測る指標である。生成品質（FIDなど）そのものではなく、生成過程が要求する不可逆性の強さと、それを実現するためにネットワークが学習して保持する情報量に焦点がある。

この指標は、同じデータ・同じ拡散設定でも、ネットワーク構造（U-Net、注意機構、MLPなど）や学習条件（データ数、ノイズスケジュール）で数値が変わる。したがって、生成物の見た目だけでは比較しにくい「内部でどれだけ情報を背負っているか」を、モデル間比較の軸として導入する意義がある。


## 2. 背景となる発想
### 2.1 拡散モデルは情報を一度消してから戻す
拡散モデルは、順方向でデータにノイズを加えていく過程（順過程）と、ノイズからデータを生成する過程（逆過程）から構成される。順過程は一般にエントロピー生成を伴う不可逆過程であり、逆過程はその不可逆性に抗して情報を注入する操作として解釈できる。

この不可逆性を定量化する道具が確率熱力学であり、時間順方向の経路分布と時間逆方向の経路分布の差（KLダイバージェンス）としてエントロピー生成を表す議論が広く用いられる。確率熱力学の日本語解説として、Langevin過程の経路確率とエントロピー生成、KLの関係が整理されている。  
参考: [2]

### 2.2 非平衡熱力学と拡散モデルの接点
拡散モデルは非平衡熱力学の視点と相性が良いが、生成誤差・ノイズスケジュール・散逸量を理論的に結びつける試みは近年活発化している。国内では、拡散モデルのノイズスケジュール選択に非平衡熱力学の不等式を用いる研究がプレスリリースとして紹介されている。  
参考: [3]

Neural Entropyは、こうした接点のうち「ネットワークが保持する情報」を、エントロピー生成と対応づけて測ろうとする点に特徴がある。拡散モデルの評価を、生成物の外形だけでなく、不可逆性と情報注入の観点で評価可能にする狙いがある。


## 3. 数理設定（拡散過程と準平衡分布）
論文では、時間反転の記述を明確にするため、順過程を新しい時間変数で書き直し、確率微分方程式（SDE）として表現する。$D$次元の順過程の一例は次の形である。

$$
dY_s = b^+(Y_s, s)\,ds + \sigma(s)\,d\hat{B}_s .
$$

ここで $b^+$ はドリフト、$\sigma(s)$ は等方的な拡散係数（スカラー）であり、$\hat{B}_s$ はブラウン運動である。拡散係数が時間依存である場合でも、一定の条件（論文では $b^+/\sigma^2$ の時間依存が揃う設定）で、後述のエントロピー生成が扱いやすい形に落ちる。

また、各時刻 $t$ のドリフトと拡散係数を固定して十分長く回したときに到達する「その時刻に対応する最小情報状態」として、準不変分布 $p^{(t)}_{\mathrm{eq}}(x)$ を定義する。これは初期状態の記憶を持たず、係数の瞬間値だけで決まる分布として機能する。


## 4. 総エントロピー生成と情報ギャップ
### 4.1 総エントロピー生成の形
拡散過程における総エントロピー生成 $S_{\mathrm{tot}}$ は、分布 $p(x,t)$ が $p^{(t)}_{\mathrm{eq}}$ からどれだけずれているかを、時間積分で測る量として表現される。論文の設定では次の形が中心である。

$$
S_{\mathrm{tot}}
=
\int_0^T dt\,\frac{\sigma(t)^2}{2}\,
\mathbb{E}_{p(\cdot,t)}
\Big[
\|\nabla \log p^{(t)}_{\mathrm{eq}} - \nabla \log p(\cdot,t)\|^2
\Big] .
$$

右辺は、順方向に拡散させたときの不可逆性（時間反転しにくさ）を表す。直感的には、準平衡（最小情報状態）からのズレが大きく、かつノイズが強い時間帯ほど、不可逆性が大きい。

### 4.2 KLによる解釈
確率熱力学では、時間順方向の経路分布と時間逆方向の経路分布のKLダイバージェンスがエントロピー生成に一致する、または境界項を除いて一致する形が繰り返し現れる。日本語の整理でも、経路の達成確率比の対数平均がKLになり、それがエントロピー生成に対応する構図が示される。  
参考: [2]

この解釈は、単なる定義の言い換えではなく、後段の「ネットワークが何を学習しているか」を、確率測度の変更（Girsanov変換や制御）として理解する入口になる。Neural Entropyは、この入口を通って拡散モデルの内部量を評価軸に持ち込む。


## 5. Entropy Matchingとネットワーク補正場
### 5.1 逆過程の理想形と、ネットワークが担う補正
順過程（ノイズ付加）を時間反転して元の分布に戻す理想的な逆過程は、スコア $\nabla \log p(x,t)$ を含む形で書かれる。論文はこの理想形に対して、実際の生成過程を「ドリフトにネットワーク出力を足す」形で表す。

$$
dX_t = \big(b^+(X_t, T-t) + \sigma(T-t)^2\,e_{\theta}(X_t,t)\big)\,dt + \sigma(T-t)\,dB_t .
$$

ここで $e_{\theta}(x,t)$ はネットワークが出力するベクトル場であり、生成を実現するための制御入力に相当する。スコアマッチングの見方ではスコア推定が主役になりやすいが、本枠組みでは「制御として必要な追加ドリフト」が主役になる。

### 5.2 Entropy Matchingの損失
論文は、準平衡スコア $\nabla \log p^{(t)}_{\mathrm{eq}}$ と、実際の分布のスコア $\nabla \log p$ の差を補正する形で $e_{\theta}$ を学習させる目的関数を与える。1次元表記の例として次が提示される（$D$次元でも同様に書ける）。

$$
\mathcal{L}_{\mathrm{EM}}
=
\int_0^T dt\,\frac{\sigma(t)^2}{2}\,
\mathbb{E}_{p(\cdot,t)}
\Big[
\|\partial_x \log p_{\mathrm{eq}} - \partial_x \log p + e_{\theta}\|^2
\Big] .
$$

この損失は、拡散の不可逆性を打ち消して目標分布へ向かわせるための「補正場」が、どれだけ適切かを測る。見方を変えると、ネットワークは準平衡からのズレを逐次測り、それを打ち消す制御則を学習している。


## 6. Neural Entropyの定義と推定式
### 6.1 理想的なNeural Entropy
理想的に学習が完璧であるとき、ネットワークが保持する情報量の下限が総エントロピー生成 $S_{\mathrm{tot}}$ に対応する、という主張が出発点になる。論文はこの理想量を Neural Entropy の基準として置く。

$$
\hat{S}_{\mathrm{NN}} := S_{\mathrm{tot}} .
$$

この定義は、生成モデルの評価を「どれだけうまく戻せたか」だけでなく、「戻すために必要な不可逆性（散逸）と同程度の情報を持てているか」という軸へ拡張する。ここでの情報はシャノン情報の比喩ではなく、経路測度の差を支える量として数式的に結びついている。

### 6.2 学習が不完全なときの実用的Neural Entropy
学習が不完全な場合、$\hat{S}_{\mathrm{NN}}$ 全てを保持できず、欠損が $\mathcal{L}_{\mathrm{EM}}$ として表に出る。論文は次の差分を Neural Entropy の実用推定として用い、さらに等価な簡約式を導く。

$$
S_{\mathrm{NN}}
:=
\hat{S}_{\mathrm{NN}} - \mathcal{L}_{\mathrm{EM}}
=
\int_0^T dt\,\frac{\sigma(t)^2}{2}\,
\mathbb{E}_{p(\cdot,t)}
\big[\|e_{\theta}(X_t,t)\|^2\big] .
$$

右端の式は非常に重要であり、Neural Entropyが「ネットワーク出力場の二乗ノルムの時間積分」という計算可能な量に落ちる。これにより、評価はスコア推定誤差や生成サンプル品質の後処理に依存せず、学習済みモデルの内部量として直接測定できる。


## 7. 測り方（数値積分とモンテカルロ）
Neural Entropyの推定は、時間積分と期待値の推定に還元されるため、基本的にはモンテカルロで実装される。時間は $t\sim \mathrm{Unif}[0,T]$ のようにサンプリングし、各 $t$ における $X_t$ を生成過程または関連分布からサンプリングして $\|e_{\theta}(X_t,t)\|^2$ を評価する。

時間方向の積分は離散化に依存するため、ノイズスケジュールが急変する区間では刻みの取り方が数値誤差に直結する。国内の拡散研究でもノイズスケジュール選択の理論根拠が議論されており、スケジュールが誤差と散逸を同時に左右する点はNeural Entropyの推定でも重要になる。  
参考: [3]


## 8. 論文が報告する主要観測と、評価指標としての読み方
### 8.1 データ数に対する対数スケーリング
論文および公式実装は、Neural Entropy $S_{\mathrm{NN}}$ が学習データ数 $N$ に対してほぼ $\log N$ スケールで増える観測を強調する。言い換えると、新しいデータを追加したときにネットワークが追加で吸収する情報量が概ね $1/N$ で減衰する。

この観測は、データ追加が常に線形に効くわけではないことを、内部量として可視化している。生成画像の品質も同様に、初期は改善が大きいが、十分なデータ量では限界効用が小さくなるという見え方になる。

### 8.2 アーキテクチャ・学習設定の比較軸
Neural Entropyは、同じデータであっても、ネットワーク構造の表現能力や誘導バイアスで変わりうる。例えば、注意機構の有無、U-Netの深さ、MLPの幅などが、同等品質に到達するまでに必要な $S_{\mathrm{NN}}$ の水準を変える可能性がある。

この点は「品質指標が同じでも、内部でどれだけ情報注入が必要か」が異なる状況を区別できることを意味する。モデル圧縮や蒸留を考える際にも、$S_{\mathrm{NN}}$ を保持したままパラメータを削れるかという観点が生じる。


## 9. 他の評価指標との比較
| 指標 | 測っている量 | 強み | 限界 |
|---|---|---|---|
| 生成品質（FIDなど） | 出力分布の外形的近さ | 人間の知覚と相関しやすい | 内部で何が起きたかは見えにくい |
| 対数尤度・下界 | 密度推定の整合性 | 理論的に明確な比較が可能 | 近似や下界評価の設計に依存しやすい |
| 学習損失（SM/DM） | 目的関数の最小化度合い | 学習過程の追跡が容易 | 指標自体が目的関数依存で横比較が難しい |
| Sharpness/平坦性 | 解の安定性の代理量 | 一般化議論と接続しやすい | 定義の揺れが大きく一意でない |
| Neural Entropy | 不可逆性に抗する情報注入量 | 拡散の物理量と直結し内部量として測定できる | 拡散モデル設定（スケジュール等）への依存が強い |

この比較表で重要なのは、Neural Entropyが「生成品質」と競合する指標ではなく、補完する指標として位置づく点である。品質が同程度でも、必要な情報注入が大きいモデルと小さいモデルがあり得るため、設計上の選好（計算量、堅牢性、データ効率）と結びつけて評価できる。


## 10. 解釈を深めるための理論的接続
### 10.1 経路測度の変更と制御コスト
$S_{\mathrm{NN}}$ が $\int \mathbb{E}[\|e_{\theta}\|^2]$ に落ちる形は、確率過程を別の確率過程へ変換する際の「制御エネルギー」として自然に現れる。確率測度の変更（Girsanov変換）の枠組みでは、ドリフト差の二乗積分が経路KLに対応することが多く、確率熱力学の整理とも整合する。  
参考: [2]

この接続は、Neural Entropyを単なる経験指標で終わらせず、設計可能な量にする。例えば、ノイズスケジュールを変えることは、積分の重み $\sigma(t)^2/2$ を時間方向で再配分することに近く、どの時間帯で情報注入が重いかを設計する問題へ落ちる。

### 10.2 散逸量・生成誤差・スケジュール選択
国内プレスリリースで述べられるように、生成誤差と熱力学的散逸を結ぶ不等式からスケジュールの選択原理を導く研究がある。Neural Entropyは散逸と直接結びつく量であるため、この種のスケジュール設計論と同じ座標系で議論しやすい。

ただし、Neural Entropyが直接に生成誤差やFIDを一意に決めるわけではない。散逸を減らす設計が必ずしも品質を保証しない可能性があるため、品質指標と併用して相関と因果を切り分ける必要がある。


## 11. 利用上の留意点
Neural Entropyは拡散係数 $\sigma(t)$ と、その下で定義された準平衡 $p^{(t)}_{\mathrm{eq}}$ を含むため、設定が変われば数値のスケールも変わる。異なる論文・異なる実装間で比較する場合、スケジュール、時間正規化、期待値の取り方（どの分布で平均するか）を揃えないと比較が破綻する。

また、$\|e_{\theta}\|^2$ は高次元で外れ値の影響を受けやすく、サンプル数が不足すると推定分散が大きくなる。推定値の不確かさは、平均値だけでなく分散や信頼区間に相当する量も併記することで、議論が安定する。


## 12. まとめと展望
Neural Entropyは、拡散モデルが不可逆なノイズ付加を逆転するために必要な情報注入を、ネットワークが担う補正場の二乗ノルム積分として定量化する指標である。これにより、生成品質の外側に、不可逆性・散逸・データ効率を横断する比較軸が導入される。

今後は、スケジュール設計とNeural Entropyの時間分解解析を結びつけ、どの時間帯で何が情報的に重いかを設計可能にする方向が有望である。さらに、生成誤差や下流タスク性能と $S_{\mathrm{NN}}$ の関係を、多データ・多アーキテクチャで系統的に検証することで、深層学習の評価が「出力」から「不可逆性に抗する内部量」へ拡張される余地がある。

### その他参考文献
A. Premkumar et al., Neural Entropy (PDF).  
https://openreview.net/pdf?id=f6AYwCvynr

公式実装（GitHub）: akhilprem1/NeuralEntropy.  
https://github.com/akhilprem1/NeuralEntropy

U. Seifert, Stochastic thermodynamics, fluctuation theorems, and molecular machines, Rep. Prog. Phys. (2012).  
https://arxiv.org/abs/1205.4176

V. De Bortoli et al., Diffusion Schrödinger Bridge with applications to score-based generative modeling (2021).  
https://arxiv.org/abs/2106.01357

S. Goldt and U. Seifert, Stochastic Thermodynamics of Learning, Phys. Rev. Lett. (2017).  
https://link.aps.org/doi/10.1103/PhysRevLett.118.010601